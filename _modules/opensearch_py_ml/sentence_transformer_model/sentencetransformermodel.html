<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>opensearch_py_ml.sentence_transformer_model.sentencetransformermodel &mdash; Opensearch-py-ml 1.0.0b1 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/plot_directive.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> Opensearch-py-ml
          </a>
              <div class="version">
                1.0.0b1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/index.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/index.html">Examples</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Opensearch-py-ml</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">opensearch_py_ml.sentence_transformer_model.sentencetransformermodel</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for opensearch_py_ml.sentence_transformer_model.sentencetransformermodel</h1><div class="highlight"><pre>
<span></span><span class="c1"># SPDX-License-Identifier: Apache-2.0</span>
<span class="c1"># The OpenSearch Contributors require contributions made to</span>
<span class="c1"># this file be licensed under the Apache-2.0 license or a</span>
<span class="c1"># compatible open source license.</span>
<span class="c1"># Any modifications Copyright OpenSearch Contributors. See</span>
<span class="c1"># GitHub history for details.</span>

<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">from</span> <span class="nn">zipfile</span> <span class="kn">import</span> <span class="n">ZipFile</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">yaml</span>
<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span><span class="p">,</span> <span class="n">notebook_launcher</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">InputExample</span><span class="p">,</span> <span class="n">SentenceTransformer</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span><span class="p">,</span> <span class="n">get_linear_schedule_with_warmup</span>


<div class="viewcode-block" id="SentenceTransformerModel"><a class="viewcode-back" href="../../../reference/api/sentence_transformer.html#opensearch_py_ml.sentence_transformer_model.SentenceTransformerModel">[docs]</a><span class="k">class</span> <span class="nc">SentenceTransformerModel</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">folder_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">overwrite</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Description:</span>
<span class="sd">        Initiate a sentence transformer model object. The model id will be used tp download pretrained model from the</span>
<span class="sd">        hugging-face and served as the default name for model files, and the folder_path will be the default location</span>
<span class="sd">        to store files generated in the following functions.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_id: str = None</span>
<span class="sd">             Optional, the huggingface mode id to download sentence transformer model,</span>
<span class="sd">             if None, default as &#39;sentence-transformers/msmarco-distilbert-base-tas-b&#39;</span>
<span class="sd">        folder_path: str = None</span>
<span class="sd">             Optional, the path of the folder to save output files, such as queries, pre-trained model, after-trained</span>
<span class="sd">             custom model and configuration files. if None, default as &quot;/model_files/&quot; under the current work directory.</span>
<span class="sd">        overwrite: bool = False</span>
<span class="sd">             Optional,  choose to overwrite the folder at folder path. Default as false. So when training different</span>
<span class="sd">             sentence transformer models,it&#39;s recommended to give designated folder path per model training. But if the</span>
<span class="sd">             training process get interrupted in between, users can choose overwrite = True to restart the process.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">default_folder_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s2">&quot;model_files&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">folder_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">folder_path</span> <span class="o">=</span> <span class="n">default_folder_path</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">folder_path</span> <span class="o">=</span> <span class="n">folder_path</span>

        <span class="c1"># check folder exist in self.folder_path</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">folder_path</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">overwrite</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;To prevent overwritten, please enter a different folder path or delete the folder or enable overwrite = True&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;The default folder path already exists at : &quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">folder_path</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">model_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_id</span> <span class="o">=</span> <span class="s2">&quot;sentence-transformers/msmarco-distilbert-base-tas-b&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_id</span> <span class="o">=</span> <span class="n">model_id</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">read_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">overwrite</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">output_model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_model_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">zip_file_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_accelerate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">compute_environment</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_machines</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">num_processes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2e-5</span><span class="p">,</span>
        <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Read the synthetic queries and use it to fine tune/train (and save) a sentence transformer model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        read_path: str</span>
<span class="sd">            required, path to the zipped file that contains generated queries, if None, raise exception.</span>
<span class="sd">            the zipped file should contain pickled file in list of dictionary format with key named as &#39;query&#39;,</span>
<span class="sd">            &#39;probability&#39; and &#39;passages&#39;. For example: [{&#39;query&#39;:q1,&#39;probability&#39;: p1,&#39;passages&#39;: pa1}, ...].</span>
<span class="sd">            &#39;probability&#39; is not required for training purpose.</span>
<span class="sd">        overwrite: bool</span>
<span class="sd">            optional, synthetic_queries/ folder in current directory is to store unzip queries files.</span>
<span class="sd">            Default to set overwrite as false and if the folder is not empty, raise exception to recommend users</span>
<span class="sd">            to either clean up folder or enable overwriting is True.</span>
<span class="sd">        output_model_path: str=None</span>
<span class="sd">            the path to store trained custom model. If None, default as current folder path</span>
<span class="sd">        output_model_name: str=None</span>
<span class="sd">            the name of the trained custom model. If None, default as model_id + &#39;.pt&#39;</span>
<span class="sd">        zip_file_name: str =None</span>
<span class="sd">            Optional, file name for zip file. if None, default as model_id + &#39;.zip&#39;</span>
<span class="sd">        use_accelerate: bool = False,</span>
<span class="sd">            Optional, use accelerate to fine tune model. Default as false to not use accelerator to fine tune model.</span>
<span class="sd">            If there are multiple gpus available in the machine, it&#39;s recommended to use accelerate with num_processor&gt;1</span>
<span class="sd">            to speeed up the training progress. If use accelerator to train model, run auto setup accelerate confi and</span>
<span class="sd">            launch train_model function with the number of processors provided by users if NOT use accelerator,</span>
<span class="sd">            trigger train_model function with default setting</span>
<span class="sd">        compute_environment: str</span>
<span class="sd">            optional, compute environment type to run model, if None, default using `LOCAL_MACHINE`</span>
<span class="sd">        num_machines: int</span>
<span class="sd">            optional, number of machine to run model , if None, default using 1</span>
<span class="sd">        num_processes: int</span>
<span class="sd">            optional, number of processors to run model , if None, default using 1</span>
<span class="sd">        learning_rate: float</span>
<span class="sd">            optional, learning rate to train model, default is 2e-5</span>
<span class="sd">        num_epochs: int</span>
<span class="sd">            optional, number of epochs to train model, default is 20</span>
<span class="sd">        verbose: bool</span>
<span class="sd">            optional, use plotting to plot the training progress. Default as false.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        None</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">query_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">read_queries</span><span class="p">(</span><span class="n">read_path</span><span class="p">,</span> <span class="n">overwrite</span><span class="p">)</span>

        <span class="n">train_examples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_sentence_transformer_example</span><span class="p">(</span>
            <span class="n">query_df</span><span class="p">,</span> <span class="n">use_accelerate</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">use_accelerate</span> <span class="ow">is</span> <span class="kc">True</span> <span class="ow">and</span> <span class="n">num_processes</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">set_up_accelerate_config</span><span class="p">(</span>
                <span class="n">compute_environment</span><span class="o">=</span><span class="n">compute_environment</span><span class="p">,</span>
                <span class="n">num_machines</span><span class="o">=</span><span class="n">num_machines</span><span class="p">,</span>
                <span class="n">num_processes</span><span class="o">=</span><span class="n">num_processes</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__is_notebook</span><span class="p">():</span>
                <span class="n">notebook_launcher</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">train_model</span><span class="p">,</span>
                    <span class="n">args</span><span class="o">=</span><span class="p">(</span>
                        <span class="n">train_examples</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">model_id</span><span class="p">,</span>
                        <span class="n">output_model_path</span><span class="p">,</span>
                        <span class="n">output_model_name</span><span class="p">,</span>
                        <span class="n">use_accelerate</span><span class="p">,</span>
                        <span class="n">learning_rate</span><span class="p">,</span>
                        <span class="n">num_epochs</span><span class="p">,</span>
                        <span class="n">verbose</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="n">num_processes</span><span class="o">=</span><span class="n">num_processes</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">subprocess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="s2">&quot;accelerate launch self.train_model(train_examples, self.model_id, output_model_path, output_model_name,use_accelerate,learning_rate,num_epochs,verbose)&quot;</span>
                    <span class="p">]</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_model</span><span class="p">(</span>
                <span class="n">train_examples</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_id</span><span class="p">,</span>
                <span class="n">output_model_path</span><span class="p">,</span>
                <span class="n">output_model_name</span><span class="p">,</span>
                <span class="n">use_accelerate</span><span class="p">,</span>
                <span class="n">learning_rate</span><span class="p">,</span>
                <span class="n">num_epochs</span><span class="p">,</span>
                <span class="n">verbose</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">zip_model</span><span class="p">(</span><span class="n">output_model_path</span><span class="p">,</span> <span class="n">output_model_name</span><span class="p">,</span> <span class="n">zip_file_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="c1">#    public step by step functions:</span>
    <span class="k">def</span> <span class="nf">read_queries</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">read_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">overwrite</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Read the queries generated from the Synthetic Query Generator (SQG) model, unzip files to current directory</span>
<span class="sd">        within synthetic_queries/ folder, output as a dataframe</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        read_path: str</span>
<span class="sd">            required, path to the zipped file that contains generated queries, if None, raise exception</span>
<span class="sd">        overwrite: bool</span>
<span class="sd">            optional, synthetic_queries/ folder in current directory is to store unzip queries files.</span>
<span class="sd">            Default to set overwrite as false and if the folder is not empty, raise exception to recommend users</span>
<span class="sd">            to either clean up folder or enable overwriting is True.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        The dataframe of queries.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">read_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="s2">&quot;No file provided. Please provide the path to synthetic query zip file.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># assign a local folder &#39;synthetic_queries/&#39; to store the unzip file,</span>
        <span class="c1"># check if the folder contains sub-folders and files, remove and clean up the folder before unzip.</span>
        <span class="c1"># walk through the zip file and read the file paths into file_list</span>
        <span class="n">unzip_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">folder_path</span><span class="p">,</span> <span class="s2">&quot;synthetic_queries&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">unzip_path</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">unzip_path</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">overwrite</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">files</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">unzip_path</span><span class="p">):</span>
                        <span class="n">sub_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">unzip_path</span><span class="p">,</span> <span class="n">files</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">sub_path</span><span class="p">):</span>
                            <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">sub_path</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">try</span><span class="p">:</span>
                                <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">sub_path</span><span class="p">)</span>
                            <span class="k">except</span> <span class="ne">OSError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
                                <span class="nb">print</span><span class="p">(</span>
                                    <span class="s2">&quot;Fail to delete files, please delete all files in &quot;</span>
                                    <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">unzip_path</span><span class="p">)</span>
                                    <span class="o">+</span> <span class="s2">&quot; &quot;</span>
                                    <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
                                <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                        <span class="s2">&quot;&#39;synthetic_queries&#39; folder is not empty, please clean up folder, or enable overwrite = &quot;</span>
                        <span class="o">+</span> <span class="s2">&quot;True. Try again. Please check &quot;</span>
                        <span class="o">+</span> <span class="n">unzip_path</span>
                    <span class="p">)</span>

        <span class="n">file_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">process</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">ZipFile</span><span class="p">(</span><span class="n">read_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
            <span class="n">zip_ref</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="n">unzip_path</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">root</span><span class="p">,</span> <span class="n">dirnames</span><span class="p">,</span> <span class="n">filenames</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="n">unzip_path</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">:</span>
                <span class="n">file_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">filename</span><span class="p">))</span>

        <span class="c1"># check empty zip file</span>
        <span class="n">num_file</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">file_list</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">num_file</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="s2">&quot;Zipped file is empty. Please provide a zip file with nonzero synthetic queries.&quot;</span>
            <span class="p">)</span>

        <span class="k">for</span> <span class="n">file_path</span> <span class="ow">in</span> <span class="n">file_list</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;reading synthetic query file: &quot;</span> <span class="o">+</span> <span class="n">file_path</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">process</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">))</span>
            <span class="k">except</span> <span class="ne">IOError</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Failed to open synthetic query file: &quot;</span> <span class="o">+</span> <span class="n">file_path</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># reading the files to get the probability, queries and passages</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">query</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">passages</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_file</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">dict_str</span> <span class="ow">in</span> <span class="n">process</span><span class="p">[</span><span class="n">j</span><span class="p">]:</span>
                <span class="k">if</span> <span class="s2">&quot;probability&quot;</span> <span class="ow">in</span> <span class="n">dict_str</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">prob</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dict_str</span><span class="p">[</span><span class="s2">&quot;probability&quot;</span><span class="p">])</span>
                <span class="k">if</span> <span class="s2">&quot;passage&quot;</span> <span class="ow">in</span> <span class="n">dict_str</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">passages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dict_str</span><span class="p">[</span><span class="s2">&quot;passage&quot;</span><span class="p">])</span>
                <span class="k">if</span> <span class="s2">&quot;query&quot;</span> <span class="ow">in</span> <span class="n">dict_str</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">query</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dict_str</span><span class="p">[</span><span class="s2">&quot;query&quot;</span><span class="p">])</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
            <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">prob</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">passages</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;prob&quot;</span><span class="p">,</span> <span class="s2">&quot;query&quot;</span><span class="p">,</span> <span class="s2">&quot;passages&quot;</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;query&quot;</span><span class="p">])</span>
        <span class="n">df</span><span class="p">[</span><span class="s2">&quot;passages&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">__qryrem</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">df</span>

    <span class="k">def</span> <span class="nf">load_sentence_transformer_example</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">use_accelerate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create input data for training</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        df: pd.DataFrame</span>
<span class="sd">            required for loading sentence transformer examples.</span>
<span class="sd">        use_accelerate: bool = False,</span>
<span class="sd">            Optional, use accelerate to fine tune model. Default as false to not use accelerator.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        the list of train examples.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">train_examples</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loading training examples... </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">use_accelerate</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)),</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):</span>
                <span class="n">train_examples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">InputExample</span><span class="p">(</span>
                        <span class="n">texts</span><span class="o">=</span><span class="p">[</span>
                            <span class="n">df</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="s2">&quot;passages&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                            <span class="n">df</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="s2">&quot;query&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                        <span class="p">]</span>
                    <span class="p">)</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">queries</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;query&quot;</span><span class="p">])</span>
            <span class="n">passages</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;passages&quot;</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)),</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):</span>
                <span class="n">train_examples</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">queries</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">passages</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
        <span class="k">return</span> <span class="n">train_examples</span>

    <span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">train_examples</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_accelerate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2e-5</span><span class="p">,</span>
        <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Description:</span>
<span class="sd">        Takes in training data and a sentence transformer url to train a custom semantic search model</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        train_examples:</span>
<span class="sd">            required, input for the sentence transformer model training</span>
<span class="sd">        model_id: str = None</span>
<span class="sd">            optional,the url to download sentence transformer model, if None, default as &#39;sentence-transformers/msmarco-distilbert-base-tas-b&#39;</span>
<span class="sd">        output_path: str=None</span>
<span class="sd">            optional,the path to store trained custom model. If None, default as default_folder_path from constructor</span>
<span class="sd">        output_model_name: str=None</span>
<span class="sd">            optional,the name of the trained custom model. If None, default as model_id + &#39;.pt&#39;</span>
<span class="sd">        use_accelerate: bool = False,</span>
<span class="sd">            Optional, use accelerate to fine tune model. Default as false to not use accelerator.</span>
<span class="sd">        learning_rate: float</span>
<span class="sd">            optional, learning rate to train model, default is 2e-5</span>
<span class="sd">        num_epochs: int</span>
<span class="sd">            optional, number of epochs to train model, default is 20</span>
<span class="sd">        verbose: float</span>
<span class="sd">            optional, use plotting to plot the training progress. Default as false.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        the torch script format trained model.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">output_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">output_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">folder_path</span>
        <span class="k">if</span> <span class="n">model_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_id</span> <span class="o">=</span> <span class="s2">&quot;sentence-transformers/msmarco-distilbert-base-tas-b&quot;</span>
        <span class="k">if</span> <span class="n">output_model_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">output_model_name</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_id</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;.pt&quot;</span><span class="p">)</span>

        <span class="c1"># prepare an output model path for later saving the pt model.</span>
        <span class="n">output_model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">output_model_name</span><span class="p">)</span>

        <span class="c1"># declare variables before assignment for training</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
        <span class="n">corp_len</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">batch_q</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Load a model from HuggingFace</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>

        <span class="c1"># Calculate the length of queries</span>
        <span class="k">if</span> <span class="n">use_accelerate</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_examples</span><span class="p">)):</span>
                <span class="n">corp_len</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_examples</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_examples</span><span class="p">)):</span>
                <span class="n">corp_len</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_examples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;texts&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)))</span>

        <span class="c1"># Calculate the length of tokenizers</span>
        <span class="c1"># We obtain the max length of the top 95% of the documents. Since this length is measured in terms of</span>
        <span class="c1"># words and not tokens we multiply it by 1.4 to approximate the fact that 1 word in the english vocabulary</span>
        <span class="c1"># roughly translates to 1.3 to 1.5 tokens. For instance the word butterfly will be split by most tokeniers into</span>
        <span class="c1"># butter and fly, but the word sun will be kept as it is.</span>
        <span class="c1"># Note that this ratio will be higher if the corpus is jargon heavy</span>
        <span class="c1"># and/or domain specific.</span>

        <span class="n">corp_max_tok_len</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">corp_len</span><span class="p">,</span> <span class="mi">95</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.4</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span> <span class="o">=</span> <span class="n">corp_max_tok_len</span>
        <span class="n">model</span><span class="o">.</span><span class="n">max_seq_length</span> <span class="o">=</span> <span class="n">corp_max_tok_len</span>

        <span class="c1"># use accelerator for training</span>
        <span class="k">if</span> <span class="n">use_accelerate</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="c1"># the default_args are required for initializing train_dataloader,</span>
            <span class="c1"># but output_dir is not used in this function.</span>
            <span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;output_dir&quot;</span><span class="p">:</span> <span class="s2">&quot;~/&quot;</span><span class="p">,</span>
                <span class="s2">&quot;evaluation_strategy&quot;</span><span class="p">:</span> <span class="s2">&quot;steps&quot;</span><span class="p">,</span>
                <span class="s2">&quot;num_train_epochs&quot;</span><span class="p">:</span> <span class="n">num_epochs</span><span class="p">,</span>
                <span class="s2">&quot;log_level&quot;</span><span class="p">:</span> <span class="s2">&quot;error&quot;</span><span class="p">,</span>
                <span class="s2">&quot;report_to&quot;</span><span class="p">:</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
                <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">fp16</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="o">**</span><span class="n">default_args</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
                <span class="n">train_examples</span><span class="p">,</span>
                <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">training_args</span><span class="o">.</span><span class="n">per_device_train_batch_size</span><span class="p">,</span>  <span class="c1"># Trains with this batch size.</span>
            <span class="p">)</span>

            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Start training with accelerator...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The number of training epoch are </span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The total number of steps training epoch are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="p">)</span>

            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
            <span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span>
                <span class="n">optimizer</span><span class="p">,</span>
                <span class="n">num_warmup_steps</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mf">0.05</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)),</span>
                <span class="n">num_training_steps</span><span class="o">=</span><span class="n">num_epochs</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span>
            <span class="p">)</span>

            <span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">(</span><span class="n">fp16</span><span class="o">=</span><span class="n">training_args</span><span class="o">.</span><span class="n">fp16</span><span class="p">)</span>
            <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">scheduler</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span>
                <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">scheduler</span>
            <span class="p">)</span>
            <span class="n">init_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="n">total_loss</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training epoch &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span>
                    <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span>
                <span class="p">):</span>

                    <span class="n">batch_q</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">batch_p</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

                    <span class="n">model</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
                    <span class="n">out_q</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">batch_q</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">out_q</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                        <span class="n">out_q</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">out_q</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

                    <span class="n">out_p</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">batch_p</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">out_p</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                        <span class="n">out_p</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">out_p</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

                    <span class="n">Y</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">out_q</span><span class="p">)[</span><span class="s2">&quot;sentence_embedding&quot;</span><span class="p">]</span>
                    <span class="n">X</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">out_p</span><span class="p">)[</span><span class="s2">&quot;sentence_embedding&quot;</span><span class="p">]</span>

                    <span class="n">XY</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>
                    <span class="n">num</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">XY</span><span class="p">)</span>

                    <span class="n">den</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">XY</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">den1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">XY</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                    <span class="n">batch_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">num</span> <span class="o">/</span> <span class="n">den</span><span class="p">))</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">num</span> <span class="o">/</span> <span class="n">den1</span><span class="p">)</span>
                    <span class="p">)</span>

                    <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">batch_loss</span><span class="p">)</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                    <span class="n">total_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

                    <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">500</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">total_loss</span><span class="p">[::</span><span class="mi">100</span><span class="p">])</span>
                        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
            <span class="n">accelerator</span><span class="o">.</span><span class="n">wait_for_everyone</span><span class="p">()</span>

        <span class="c1"># IF ACCELERATE IS FALSE</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># identify if running on gpu or cpu</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">total_steps</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_examples</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">)</span> <span class="o">*</span> <span class="n">num_epochs</span>
            <span class="n">steps_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_examples</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
            <span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span>
                <span class="n">optimizer</span><span class="p">,</span>
                <span class="n">num_warmup_steps</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="n">total_steps</span> <span class="o">*</span> <span class="mf">0.05</span><span class="p">),</span>
                <span class="n">num_training_steps</span><span class="o">=</span><span class="n">total_steps</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">init_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Start training without accelerator...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The number of training epoch are </span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The total number of steps training epoch are </span><span class="si">{</span><span class="n">steps_size</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
                <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">train_examples</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training epoch &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">steps_size</span><span class="p">),</span> <span class="n">total</span><span class="o">=</span><span class="n">steps_size</span><span class="p">):</span>
                    <span class="n">batch</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="n">batch_q</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">train_examples</span><span class="p">[</span>
                        <span class="n">j</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="p">:</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span>
                    <span class="p">]:</span>
                        <span class="n">batch_q</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">texts</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                        <span class="n">batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">texts</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

                    <span class="n">out_q</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">batch_q</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">out_q</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                        <span class="n">out_q</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">out_q</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">Y</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">out_q</span><span class="p">)[</span><span class="s2">&quot;sentence_embedding&quot;</span><span class="p">]</span>

                    <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">out</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                        <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">X</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">out</span><span class="p">)[</span><span class="s2">&quot;sentence_embedding&quot;</span><span class="p">]</span>

                    <span class="n">XY</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>
                    <span class="n">num</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">XY</span><span class="p">)</span>

                    <span class="n">den0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">XY</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">den1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">XY</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                    <span class="n">train_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">num</span> <span class="o">/</span> <span class="n">den0</span><span class="p">))</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">num</span> <span class="o">/</span> <span class="n">den1</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="n">loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                    <span class="n">train_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                    <span class="k">if</span> <span class="ow">not</span> <span class="n">j</span> <span class="o">%</span> <span class="mi">500</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss</span><span class="p">[::</span><span class="mi">100</span><span class="p">])</span>
                        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

        <span class="c1"># saving the pytorch model and the tokenizers.json file is saving at this step</span>
        <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">output_path</span><span class="p">)</span>
        <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span>
        <span class="n">cpu_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total training time: </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">init_time</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">out_q</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">out_q</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">out_q</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">traced_cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span>
            <span class="n">cpu_model</span><span class="p">,</span>
            <span class="p">(</span>
                <span class="p">{</span>
                    <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">out_q</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">],</span>
                    <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">out_q</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">],</span>
                <span class="p">}</span>
            <span class="p">),</span>
            <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Preparing model to save...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">traced_cpu</span><span class="p">,</span> <span class="n">output_model_path</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model saved to path: &quot;</span> <span class="o">+</span> <span class="n">output_model_path</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">traced_cpu</span>

    <span class="k">def</span> <span class="nf">zip_model</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">zip_file_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Description:</span>
<span class="sd">        zip the model file and its tokenizer.json file to prepare to upload to the Open Search cluster</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_path: str</span>
<span class="sd">            Optional, path to find the model file, if None, default as concatenate model_id and &#39;.pt&#39; file in current path</span>
<span class="sd">        model_name: str=None</span>
<span class="sd">            the name of the trained custom model. If None, default as concatenate model_id and &#39;.pt&#39;</span>
<span class="sd">        zip_file_name: str =None</span>
<span class="sd">            Optional, file name for zip file. if None, default as concatenate model_id and &#39;.zip&#39;</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">model_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_name</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_id</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;.pt&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">model_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">folder_path</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">model_name</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">model_name</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">zip_file_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">zip_file_name</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">model_name</span> <span class="o">+</span> <span class="s2">&quot;.zip&quot;</span><span class="p">)</span>

        <span class="n">tokenizer_json_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">folder_path</span><span class="p">,</span> <span class="s2">&quot;tokenizer.json&quot;</span><span class="p">)</span>
        <span class="n">zip_file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">folder_path</span><span class="p">,</span> <span class="n">zip_file_name</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">tokenizer_json_path</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="s2">&quot;Cannot find tokenizer.json file, please check at &quot;</span>
                <span class="o">+</span> <span class="n">tokenizer_json_path</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">model_path</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="s2">&quot;Cannot find model in the model path , please check at &quot;</span> <span class="o">+</span> <span class="n">model_path</span>
            <span class="p">)</span>

        <span class="c1"># Create a ZipFile Object</span>
        <span class="k">with</span> <span class="n">ZipFile</span><span class="p">(</span><span class="n">zip_file_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">zipObj</span><span class="p">:</span>
            <span class="n">zipObj</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
            <span class="n">zipObj</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">tokenizer_json_path</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;zip file is saved to &quot;</span> <span class="o">+</span> <span class="n">zip_file_path</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">save_as_pt</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">sentences</span><span class="p">:</span> <span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">save_json_folder_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">zip_file_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        download sentence transformer model directly from huggingface, convert model to torch script format,</span>
<span class="sd">        zip the model file and its tokenizer.json file to prepare to upload to the Open Search cluster</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        sentences:[str]</span>
<span class="sd">            Required, for example  sentences = [&#39;today is sunny&#39;]</span>
<span class="sd">        model: str</span>
<span class="sd">            Optional, if provide model in parameters, will convert model to torch script format,</span>
<span class="sd">            else, not provided model then it will download sentence transformer model from huggingface.</span>
<span class="sd">            If None, default takes model_id = &quot;sentence-transformers/msmarco-distilbert-base-tas-b&quot;.</span>
<span class="sd">        model_name: str</span>
<span class="sd">            Optional, model name to name the model file, e.g, &quot;sample_model.pt&quot;. If None, default takes the</span>
<span class="sd">            model_id and add the extension with &quot;.pt&quot;.</span>
<span class="sd">        save_json_folder_path:</span>
<span class="sd">             Optional, path to save model json file, e.g, &quot;home/save_pre_trained_model_json/&quot;). If None, default as</span>
<span class="sd">             default_folder_path from the constructor.</span>
<span class="sd">        zip_file_name: str =None</span>
<span class="sd">            Optional, file name for zip file. e.g, &quot;sample_model.zip&quot;. If None, default takes the model_id</span>
<span class="sd">            and add the extension with &quot;.zip&quot;.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        the torch script format model</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_id</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">model_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_name</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_id</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;.pt&quot;</span><span class="p">)</span>

        <span class="n">model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">folder_path</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">save_json_folder_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">save_json_folder_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">folder_path</span>

        <span class="k">if</span> <span class="n">zip_file_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">zip_file_name</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_id</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;.zip&quot;</span><span class="p">)</span>
        <span class="n">zip_file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">folder_path</span><span class="p">,</span> <span class="n">zip_file_name</span><span class="p">)</span>

        <span class="c1"># save tokenizer.json in save_json_folder_name</span>
        <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">save_json_folder_path</span><span class="p">)</span>

        <span class="c1"># convert to pt format will need to be in cpu,</span>
        <span class="c1"># set the device to cpu, convert its input_ids and attention_mask in cpu and save as .pt format</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">cpu_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">cpu_model</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
        <span class="n">out_q</span> <span class="o">=</span> <span class="n">features</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">out_q</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">out_q</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="n">compiled_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span>
            <span class="n">cpu_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">),</span>
            <span class="p">({</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">input_ids</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">attention_mask</span><span class="p">}),</span>
            <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">compiled_model</span><span class="p">,</span> <span class="n">model_path</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;model file is saved to &quot;</span><span class="p">,</span> <span class="n">model_path</span><span class="p">)</span>

        <span class="c1"># zip model file along with tokenizer.json as output</span>
        <span class="k">with</span> <span class="n">ZipFile</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">zip_file_path</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">zipObj</span><span class="p">:</span>
            <span class="n">zipObj</span><span class="o">.</span><span class="n">write</span><span class="p">(</span>
                <span class="n">model_path</span><span class="p">,</span>
                <span class="n">arcname</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">model_name</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="n">zipObj</span><span class="o">.</span><span class="n">write</span><span class="p">(</span>
                <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_json_folder_path</span><span class="p">,</span> <span class="s2">&quot;tokenizer.json&quot;</span><span class="p">),</span>
                <span class="n">arcname</span><span class="o">=</span><span class="s2">&quot;tokenizer.json&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;zip file is saved to &quot;</span><span class="p">,</span> <span class="n">zip_file_path</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">compiled_model</span>

    <span class="k">def</span> <span class="nf">set_up_accelerate_config</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">compute_environment</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_machines</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">num_processes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        get default config setting based on the number of GPU on the machine</span>
<span class="sd">        if users require other configs, users can run !acclerate config for more options.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        compute_environment: str</span>
<span class="sd">            optional, compute environment type to run model, if None, default using &#39;LOCAL_MACHINE&#39;</span>
<span class="sd">        num_machines: int</span>
<span class="sd">            optional, number of machine to run model , if None, default using 1</span>
<span class="sd">        num_processes: int</span>
<span class="sd">            optional, number of processes to run model, if None, default to check how many gpus are available and use all.</span>
<span class="sd">            if no gpu is available, use cpu.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        None</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">compute_environment</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">compute_environment</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">compute_environment</span> <span class="o">=</span> <span class="s2">&quot;LOCAL_MACHINE&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">subprocess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;accelerate config&quot;</span><span class="p">)</span>
            <span class="k">return</span>

        <span class="n">hf_cache_home</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span>
            <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span>
                <span class="s2">&quot;HF_HOME&quot;</span><span class="p">,</span>
                <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;XDG_CACHE_HOME&quot;</span><span class="p">,</span> <span class="s2">&quot;~/.cache&quot;</span><span class="p">),</span> <span class="s2">&quot;huggingface&quot;</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="n">cache_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">hf_cache_home</span><span class="p">,</span> <span class="s2">&quot;accelerate&quot;</span><span class="p">)</span>

        <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cache_dir</span><span class="p">,</span> <span class="s2">&quot;default_config.yaml&quot;</span><span class="p">)</span>
        <span class="n">use_cpu</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;generated config file: at &quot;</span> <span class="o">+</span> <span class="n">file_path</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">file_path</span><span class="p">),</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">num_processes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="n">num_processes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">num_processes</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="n">use_cpu</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">model_config_content</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;compute_environment&quot;</span><span class="p">:</span> <span class="n">compute_environment</span><span class="p">,</span>
                <span class="s2">&quot;deepspeed_config&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;gradient_accumulation_steps&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
                    <span class="s2">&quot;offload_optimizer_device&quot;</span><span class="p">:</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;offload_param_device&quot;</span><span class="p">:</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;zero3_init_flag&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                    <span class="s2">&quot;zero_stage&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
                <span class="p">},</span>
                <span class="s2">&quot;distributed_type&quot;</span><span class="p">:</span> <span class="s2">&quot;DEEPSPEED&quot;</span><span class="p">,</span>
                <span class="s2">&quot;downcast_bf16&quot;</span><span class="p">:</span> <span class="s2">&quot;no&quot;</span><span class="p">,</span>
                <span class="s2">&quot;fsdp_config&quot;</span><span class="p">:</span> <span class="p">{},</span>
                <span class="s2">&quot;machine_rank&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s2">&quot;main_process_ip&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;main_process_port&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;main_training_function&quot;</span><span class="p">:</span> <span class="s2">&quot;main&quot;</span><span class="p">,</span>
                <span class="s2">&quot;mixed_precision&quot;</span><span class="p">:</span> <span class="s2">&quot;no&quot;</span><span class="p">,</span>
                <span class="s2">&quot;num_machines&quot;</span><span class="p">:</span> <span class="n">num_machines</span><span class="p">,</span>
                <span class="s2">&quot;num_processes&quot;</span><span class="p">:</span> <span class="n">num_processes</span><span class="p">,</span>
                <span class="s2">&quot;use_cpu&quot;</span><span class="p">:</span> <span class="n">use_cpu</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">model_config_content</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="s2">&quot;generating config file for ml common upload: &quot;</span> <span class="o">+</span> <span class="n">file_path</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="p">)</span>
                <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">model_config_content</span><span class="p">,</span> <span class="n">file</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">IOError</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;Failed to open config file for ml common upload: &quot;</span> <span class="o">+</span> <span class="n">file_path</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">make_model_config_json</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">version_number</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">embedding_dimension</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">all_config</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        parse from config.json file of pre-trained hugging-face model to generate a ml-commons_model_config.json file. If all required</span>
<span class="sd">        fields are given by users, use the given parameters and will skip reading the config.json,</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_name: str = None</span>
<span class="sd">            Optional, The name of the model. If None, default to parse from model id, for example,</span>
<span class="sd">            &#39;msmarco-distilbert-base-tas-b&#39;</span>
<span class="sd">        version_number: int = 1,</span>
<span class="sd">            Optional, The version number of the model. If None, default to be 1.</span>
<span class="sd">        embedding_dimension: int = 768,</span>
<span class="sd">            Optional, the embedding_dimension of the model. If None, parse embedding_dimension from the config file of</span>
<span class="sd">             pre-trained hugging-face model, if not found, default to be 768.</span>
<span class="sd">        all_config: dict = None,</span>
<span class="sd">            Optional, the all_config of the model. If None, parse all contents from the config file of pre-trained</span>
<span class="sd">            hugging-face model.</span>
<span class="sd">        model_type: str = None,</span>
<span class="sd">            Optional, the model_type of the model. If None, parse model_type from the config file of pre-trained</span>
<span class="sd">            hugging-face model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">folder_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">folder_path</span>
        <span class="n">config_json_file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder_path</span><span class="p">,</span> <span class="s2">&quot;config.json&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">model_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_id</span>

        <span class="c1"># if user input model_type and embedding_dimension, it will skip reading the config.json file</span>
        <span class="k">if</span> <span class="n">model_type</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">embedding_dimension</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">config_json_file_path</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                    <span class="nb">str</span><span class="p">(</span>
                        <span class="s2">&quot;Cannot find config.json in&quot;</span>
                        <span class="o">+</span> <span class="n">config_json_file_path</span>
                        <span class="o">+</span> <span class="s2">&quot;. Please check the config.son file in the path.&quot;</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_json_file_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;reading config file: at&quot;</span> <span class="o">+</span> <span class="n">config_json_file_path</span><span class="p">)</span>
                    <span class="n">config_content</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">all_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">all_config</span> <span class="o">=</span> <span class="n">config_content</span>
                    <span class="k">if</span> <span class="n">model_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">if</span> <span class="s2">&quot;model_type&quot;</span> <span class="ow">in</span> <span class="n">config_content</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                            <span class="n">model_type</span> <span class="o">=</span> <span class="n">config_content</span><span class="p">[</span><span class="s2">&quot;model_type&quot;</span><span class="p">]</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="nb">print</span><span class="p">(</span>
                                <span class="s2">&quot;Please check file or input model_type and embedding_dimension in the argument&quot;</span>
                            <span class="p">)</span>
                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                                <span class="nb">str</span><span class="p">(</span>
                                    <span class="s2">&quot;Cannot find model_type in config.json file&quot;</span>
                                    <span class="o">+</span> <span class="n">config_json_file_path</span>
                                    <span class="o">+</span> <span class="s2">&quot;. Please check the config.son file in the path.&quot;</span>
                                <span class="p">)</span>
                            <span class="p">)</span>
                    <span class="k">if</span> <span class="n">embedding_dimension</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">embedding_dimension_mapping_list</span> <span class="o">=</span> <span class="p">[</span>
                            <span class="s2">&quot;dim&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;hidden_size&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;d_model&quot;</span><span class="p">,</span>
                        <span class="p">]</span>
                        <span class="k">for</span> <span class="n">mapping_item</span> <span class="ow">in</span> <span class="n">embedding_dimension_mapping_list</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">mapping_item</span> <span class="ow">in</span> <span class="n">config_content</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                                <span class="n">embedding_dimension</span> <span class="o">=</span> <span class="n">config_content</span><span class="p">[</span><span class="n">mapping_item</span><span class="p">]</span>
                                <span class="k">break</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="nb">print</span><span class="p">(</span>
                                    <span class="s1">&#39;Cannot find &quot;dim&quot; or &quot;hidden_size&quot; or &quot;d_model&quot; in config.json file at &#39;</span><span class="p">,</span>
                                    <span class="n">config_json_file_path</span><span class="p">,</span>
                                <span class="p">)</span>
                                <span class="nb">print</span><span class="p">(</span>
                                    <span class="s2">&quot;Please add in the config file or input in the argument for embedding_dimension &quot;</span>
                                <span class="p">)</span>
                                <span class="n">embedding_dimension</span> <span class="o">=</span> <span class="mi">768</span>
            <span class="k">except</span> <span class="ne">IOError</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="s2">&quot;Cannot open in config.json file at &quot;</span><span class="p">,</span>
                    <span class="n">config_json_file_path</span><span class="p">,</span>
                    <span class="s2">&quot;. Please check the config.son &quot;</span><span class="p">,</span>
                    <span class="s2">&quot;file in the path.&quot;</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="n">model_config_content</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">model_name</span><span class="p">,</span>
            <span class="s2">&quot;version&quot;</span><span class="p">:</span> <span class="n">version_number</span><span class="p">,</span>
            <span class="s2">&quot;model_format&quot;</span><span class="p">:</span> <span class="s2">&quot;TORCH_SCRIPT&quot;</span><span class="p">,</span>
            <span class="s2">&quot;model_task_type&quot;</span><span class="p">:</span> <span class="s2">&quot;TEXT_EMBEDDING&quot;</span><span class="p">,</span>
            <span class="s2">&quot;model_config&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;model_type&quot;</span><span class="p">:</span> <span class="n">model_type</span><span class="p">,</span>
                <span class="s2">&quot;embedding_dimension&quot;</span><span class="p">:</span> <span class="n">embedding_dimension</span><span class="p">,</span>
                <span class="s2">&quot;framework_type&quot;</span><span class="p">:</span> <span class="s2">&quot;sentence_transformers&quot;</span><span class="p">,</span>
                <span class="s2">&quot;all_config&quot;</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">all_config</span><span class="p">),</span>
            <span class="p">},</span>
        <span class="p">}</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;generating ml-commons_model_config.json file...&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">model_config_content</span><span class="p">)</span>

        <span class="n">model_config_file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="n">folder_path</span><span class="p">,</span> <span class="s2">&quot;ml-commons_model_config.json&quot;</span>
        <span class="p">)</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">model_config_file_path</span><span class="p">),</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">model_config_file_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">model_config_content</span><span class="p">,</span> <span class="n">file</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s2">&quot;ml-commons_model_config.json file is saved at&quot;</span><span class="p">,</span> <span class="n">model_config_file_path</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># private methods</span>
    <span class="k">def</span> <span class="nf">__qryrem</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># for removing the &quot;QRY:&quot; token if they exist in passages</span>
        <span class="k">if</span> <span class="s2">&quot;QRY:&quot;</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">passages</span> <span class="ow">and</span> <span class="s2">&quot;&lt;|startoftext|&gt;&quot;</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">passages</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">passages</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; QRY:&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;&lt;|startoftext|&gt;&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">__is_notebook</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">shell</span> <span class="o">=</span> <span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
            <span class="c1"># Jupyter notebook or qtconsole</span>
            <span class="k">if</span> <span class="n">shell</span> <span class="o">==</span> <span class="s2">&quot;ZMQInteractiveShell&quot;</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">True</span>
                <span class="c1"># Terminal running IPython</span>
            <span class="k">elif</span> <span class="n">shell</span> <span class="o">==</span> <span class="s2">&quot;TerminalInteractiveShell&quot;</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>
        <span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
            <span class="c1"># Probably standard Python interpreter</span>
            <span class="k">return</span> <span class="kc">False</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Opensearch.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>